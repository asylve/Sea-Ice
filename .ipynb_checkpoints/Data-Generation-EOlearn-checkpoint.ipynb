{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "numeric-protocol",
   "metadata": {},
   "source": [
    "https://eo-learn.readthedocs.io/en/latest/examples/land-cover-map/SI_LULC_pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-thinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\seaice10\\lib\\site-packages\\eolearn\\io\\processing_api.py:176: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ProcApiType(\"bool_mask\", 'DN', 'UINT8', np.bool, FeatureType.MASK): [\n"
     ]
    }
   ],
   "source": [
    "# Firstly, some necessary imports\n",
    "\n",
    "# Jupyter notebook related\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Built-in modules\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "from aenum import MultiValueEnum\n",
    "\n",
    "# Basics of Python data handling and visualization\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Imports from eo-learn and sentinelhub-py\n",
    "from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
    "    LoadTask, SaveTask, EOExecutor, ExtractBandsTask, MergeFeatureTask\n",
    "from eolearn.io import SentinelHubInputTask, ExportToTiff\n",
    "from eolearn.mask import AddMultiCloudMaskTask, AddValidDataMaskTask\n",
    "from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\n",
    "from eolearn.features import LinearInterpolation, SimpleFilterTask, NormalizedDifferenceIndexTask\n",
    "from sentinelhub import UtmZoneSplitter, BBox, CRS, DataCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geojson file\n",
    "ice_gdf = gpd.read_file('data/cis_SGRDRHB_20200525T1800Z_pl_a.shp')#load shape file inclusing sea ice concentration data\n",
    "ice_gdf = ice_gdf.to_crs('EPSG:32617')\n",
    "\n",
    "region = ice_gdf.dropna()#remove polygons where there is not data (corresponds to land)\n",
    "region = region.geometry.unary_union#get the untion of all the water area\n",
    "region = gpd.GeoDataFrame(geometry=[region], crs=ice_gdf.crs)\n",
    "\n",
    "# region = region.buffer(500)\n",
    "\n",
    "# Get the country's shape in polygon format\n",
    "region_shape = region.geometry.values[-1]\n",
    "\n",
    "# Plot country\n",
    "region.plot()\n",
    "\n",
    "# Print size\n",
    "print('Dimension of the area is {0:.0f} x {1:.0f} m2'.format(region_shape.bounds[2] - region_shape.bounds[0],\n",
    "                                                             region_shape.bounds[3] - region_shape.bounds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import BBoxSplitter\n",
    "# Create the splitter to obtain a list of bboxes\n",
    "bbox_splitter = BBoxSplitter([region_shape], region.crs, (35, 35))\n",
    "\n",
    "bbox_list = np.array(bbox_splitter.get_bbox_list())\n",
    "info_list = np.array(bbox_splitter.get_info_list())\n",
    "for n, info in enumerate(info_list):\n",
    "    info['index']=n\n",
    "\n",
    "# Prepare info of selected EOPatches\n",
    "geometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list]\n",
    "idxs = [info['index'] for info in info_list]\n",
    "idxs_x = [info['index_x'] for info in info_list]\n",
    "idxs_y = [info['index_y'] for info in info_list]\n",
    "\n",
    "gdf = gpd.GeoDataFrame({'index': idxs, 'index_x': idxs_x, 'index_y': idxs_y},\n",
    "                           crs=region.crs,\n",
    "                           geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-logging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select a 3x3 area (id of center patch)\n",
    "ID = 294\n",
    "\n",
    "# Obtain surrounding 5x5 patches\n",
    "patchIDs = []\n",
    "for idx, [bbox, info] in enumerate(zip(bbox_list, info_list)):\n",
    "    if (abs(info['index_x'] - info_list[ID]['index_x']) <= 1 and\n",
    "        abs(info['index_y'] - info_list[ID]['index_y']) <= 1):\n",
    "        patchIDs.append(idx)\n",
    "\n",
    "# Check if final size is 3x3\n",
    "if len(patchIDs) != 3*3:\n",
    "    print('Warning! Use a different central patch ID, this one is on the border.')\n",
    "\n",
    "# Change the order of the patches (used for plotting later)\n",
    "patchIDs = np.transpose(np.fliplr(np.array(patchIDs).reshape(3, 3))).ravel()\n",
    "\n",
    "# save to shapefile\n",
    "shapefile_name = './grid_sea_ice.gpkg'\n",
    "gdf.to_file(shapefile_name, driver='GPKG')\n",
    "\n",
    "# figure\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "gdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5)\n",
    "region.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5)\n",
    "ax.set_title('Selected 3x3 Tiles', fontsize=25);\n",
    "for bbox, info in zip(bbox_list, info_list):\n",
    "    geo = bbox.geometry\n",
    "    ax.text(geo.centroid.x, geo.centroid.y, info['index'], ha='center', va='center', size=18)\n",
    "\n",
    "gdf[gdf.index.isin(patchIDs)].plot(ax=ax,facecolor='g',edgecolor='r',alpha=0.5)\n",
    "\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentinelHubValidData:\n",
    "    \"\"\"\n",
    "    Combine Sen2Cor's classification map with `IS_DATA` to define a `VALID_DATA_SH` mask\n",
    "    The SentinelHub's cloud mask is asumed to be found in eopatch.mask['CLM']\n",
    "    \"\"\"\n",
    "    def __call__(self, eopatch):\n",
    "        return np.logical_and(eopatch.mask['IS_DATA'].astype(np.bool),\n",
    "                              np.logical_not(eopatch.mask['CLM'].astype(np.bool)))\n",
    "\n",
    "class CountValid(EOTask):\n",
    "    \"\"\"\n",
    "    The task counts number of valid observations in time-series and stores the results in the timeless mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, count_what, feature_name):\n",
    "        self.what = count_what\n",
    "        self.name = feature_name\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.name, np.count_nonzero(eopatch.mask[self.what],axis=0))\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task for downloading saetlite data\n",
    "band_names = ['B03', 'B04', 'B08']\n",
    "add_data = SentinelHubInputTask(\n",
    "    bands_feature=(FeatureType.DATA, 'BANDS'),\n",
    "    bands = band_names,\n",
    "    resolution=200,\n",
    "    maxcc=0.8,\n",
    "    time_difference=datetime.timedelta(minutes=120),\n",
    "    data_collection=DataCollection.SENTINEL2_L1C,\n",
    "    additional_data=[(FeatureType.MASK, 'dataMask', 'IS_DATA'),\n",
    "                     (FeatureType.MASK, 'CLM'),]\n",
    ")\n",
    "\n",
    "# TASK FOR SAVING TO OUTPUT (if needed)\n",
    "path_out = './eopatches/'\n",
    "if not os.path.isdir(path_out):\n",
    "    os.makedirs(path_out)\n",
    "save = SaveTask(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "# TASK FOR SAVING TO OUTPUT (if needed)\n",
    "path_out = './eopatches/'\n",
    "if not os.path.isdir(path_out):\n",
    "    os.makedirs(path_out)\n",
    "save = SaveTask(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "# #adding mask\n",
    "# land_use_ref = gpd.read_file('data/ice_charts/2019/cis_SGRDRHB_20190520T1800Z_pl_b_20190522205156/cis_SGRDRHB_20190520T1800Z_pl_b.shp')\n",
    "# land_use_ref.fillna(-100, inplace=True)\n",
    "# land_use_ref['CT'] = land_use_ref['CT'].astype('int')\n",
    "# land_use_ref = land_use_ref.to_crs(region.crs)\n",
    "\n",
    "# rasterization_task = VectorToRaster(land_use_ref, (FeatureType.MASK_TIMELESS, 'LULC'),\n",
    "#                                     values_column='CT', raster_shape=(FeatureType.DATA, 'BANDS'),\n",
    "#                                     raster_dtype=np.int16, no_data_value=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_data_mask(eopatch):\n",
    "    is_data_mask = eopatch.mask['IS_DATA'].astype(np.bool)\n",
    "    cloud_mask = ~eopatch.mask['CLM'].astype(np.bool)\n",
    "    return np.logical_and(is_data_mask, cloud_mask)\n",
    "\n",
    "add_valid_mask = AddValidDataMaskTask(predicate=calculate_valid_data_mask, valid_data_feature='VALID_DATA')\n",
    "\n",
    "def calculate_coverage(array):\n",
    "    return 1.0 - np.count_nonzero(array) / np.size(array)\n",
    "\n",
    "class AddValidDataCoverage(EOTask):\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "\n",
    "        valid_data = eopatch.get_feature(FeatureType.MASK, 'VALID_DATA')\n",
    "        time, height, width, channels = valid_data.shape\n",
    "\n",
    "        coverage = np.apply_along_axis(calculate_coverage, 1,\n",
    "                                       valid_data.reshape((time, height * width * channels)))\n",
    "\n",
    "        eopatch.add_feature(FeatureType.SCALAR, 'COVERAGE', coverage[:, np.newaxis])\n",
    "        return eopatch\n",
    "\n",
    "add_coverage = AddValidDataCoverage()\n",
    "\n",
    "cloud_coverage_threshold = 0.10\n",
    "\n",
    "class ValidDataCoveragePredicate:\n",
    "\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, array):\n",
    "        return calculate_coverage(array) < self.threshold\n",
    "\n",
    "remove_cloudy_scenes = SimpleFilterTask((FeatureType.MASK, 'VALID_DATA'),\n",
    "                                        ValidDataCoveragePredicate(cloud_coverage_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = LinearWorkflow(\n",
    "    add_data,\n",
    "    add_valid_mask,\n",
    "    add_coverage, \n",
    "    remove_cloudy_scenes,\n",
    "    time_raster,\n",
    "    save,)\n",
    "# Let's visualize it\n",
    "workflow.dependency_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-reminder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Execute the workflow\n",
    "time_interval = ['2019-05-01', '2019-5-30'] # time interval for the SH request\n",
    "\n",
    "# define additional parameters of the workflow\n",
    "execution_args = []\n",
    "for idx, bbox in enumerate(bbox_list[patchIDs]):\n",
    "    execution_args.append({\n",
    "        add_data:{'bbox': bbox, 'time_interval': time_interval},\n",
    "        save: {'eopatch_folder': f'eopatch_{idx}'}\n",
    "    })\n",
    "#     print(execution_args[0])\n",
    "\n",
    "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
    "executor.run()\n",
    "\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(9):\n",
    "    try:\n",
    "        eopatch = EOPatch.load('./eopatches/eopatch_{}/'.format(id),  lazy_loading=True)\n",
    "        # fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "        # ax.imshow(eopatch.mask['VALID_DATA'][0])\n",
    "        print(id)\n",
    "        print(eopatch.timestamp)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = EOPatch.load('./eopatches/eopatch_5/',  lazy_loading=True)\n",
    "\n",
    "chart_dir = \"./data/ice_charts/2019\"\n",
    "base_len=31#the base naming of the folder and files(without the extension)\n",
    "\n",
    "chart_folders = [name for name in os.listdir(chart_dir)]#all the sea ice chart folders available\n",
    "chart_dates = np.array([datetime.datetime.strptime(name.split('_')[2][:8], '%Y%m%d') for name in os.listdir(chart_dir)])#all the dates available\n",
    "chart_dates = chart_dates+datetime.timedelta(hours=12)#add 12 hours to the date so it is in the middle of the day\n",
    "\n",
    "def get_nearest_chart_dates(eop):#given an eopatch, return the dates of the closest available ice charts for each image\n",
    "    sat_dates = np.array(eop.timestamp)\n",
    "    mask_dates=[]\n",
    "\n",
    "    for date in sat_dates:\n",
    "        closest_date_id = np.argsort(abs(date-chart_dates))[0]\n",
    "        closest_date = chart_dates[closest_date_id]\n",
    "        mask_dates.append(closest_date)\n",
    "    return(mask_dates)\n",
    "\n",
    "def get_path(date):#get the file path of the sea ice shapefile corresponding to a date\n",
    "    names = [name for name in chart_folders if date.strftime('%Y%m%d') in name]#get all the the folder names that match the date\n",
    "    folder = max(names, key=len) #get the longest named folder (this is the most recent revision in case the folder was updated)\n",
    "    if len(folder)>base_len:\n",
    "        file = folder[:31]\n",
    "    else: \n",
    "        file = folder\n",
    "    return '/'+folder+'/'+file+'.shp'\n",
    "\n",
    "m_dates = get_nearest_chart_dates(eopatch)\n",
    "[get_path(date) for date in m_dates]\n",
    "m_dates[0].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch.data['BANDS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRaster(EOTask):\n",
    "    \n",
    "    def __init__(self, chart_dir, base_len):\n",
    "        self.chart_dir = chart_dir\n",
    "        self.base_len = base_len\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        \n",
    "        chart_folders = [name for name in os.listdir(chart_dir)]#all the sea ice chart folders available\n",
    "        chart_dates = np.array([datetime.datetime.strptime(name.split('_')[2][:8], '%Y%m%d') for name in os.listdir(chart_dir)])#all the dates available\n",
    "        chart_dates = chart_dates+datetime.timedelta(hours=12)#add 12 hours to the date so it is in the middle of the day\n",
    "        \n",
    "        #get the ice chart dates corresponding to the image dates\n",
    "        sat_dates = np.array(eopatch.timestamp)#get the dates for each image in the eopatch\n",
    "        mask_dates=[]#this will hold the dates of the ice chart associated with each satellite image\n",
    "        for date in sat_dates:\n",
    "            closest_date_id = np.argsort(abs(date-chart_dates))[0]\n",
    "            closest_date = chart_dates[closest_date_id]#closest ice chart date to the image date\n",
    "            mask_dates.append(closest_date)\n",
    "        \n",
    "        eopatch.add_feature(FeatureType.SCALAR_TIMELESS, 'TEST', np.array(mask_dates))\n",
    "        return eopatch\n",
    "#         chart_paths = []\n",
    "#         #get the paths of the ice charts corresponding to the images\n",
    "#         for date in mask_dates:\n",
    "#             names = [name for name in chart_folders if date.strftime('%Y%m%d') in name]#get all the the folder names that match the date\n",
    "#             folder = max(names, key=len) #get the longest named folder (this is the most recent revision in case the folder was updated)\n",
    "#             if len(folder)>base_len:\n",
    "#                 file = folder[:31]\n",
    "#             else: \n",
    "#                 file = folder\n",
    "#             chart_paths.append('/'+folder+'/'+file+'.shp')\n",
    "        \n",
    "        \n",
    "#         add_raster = VectorToRaster(land_use_ref, (FeatureType.MASK_TIMELESS, 'TEST'),\n",
    "#                                     values_column='CT', raster_shape=(FeatureType.DATA, 'BANDS'),\n",
    "#                                     raster_dtype=np.int16, no_data_value=-100)\n",
    "#         add_raster(eopatch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#         valid_data = eopatch.get_feature(FeatureType.MASK, 'VALID_DATA')\n",
    "#         time, height, width, channels = valid_data.shape\n",
    "\n",
    "#         coverage = np.apply_along_axis(calculate_coverage, 1,\n",
    "#                                        valid_data.reshape((time, height * width * channels)))\n",
    "\n",
    "#         eopatch.add_feature(FeatureType.SCALAR, 'COVERAGE', coverage[:, np.newaxis])\n",
    "\n",
    "time_raster = TimeRaster(chart_dir, base_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch.mask_timeless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the RGB image\n",
    "date = datetime.datetime(2019,5,14)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 8))\n",
    "\n",
    "print(date)\n",
    "eopatch = EOPatch.load('./eopatches/eopatch_5/',  lazy_loading=True)\n",
    "dates = np.array(eopatch.timestamp)\n",
    "closest_date_id = np.argsort(abs(date-dates))[0]\n",
    "axs[0].imshow(np.clip(eopatch.data['BANDS'][closest_date_id][..., [2, 1, 0]] * 3.5, 0, 1))\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "axs[0].set_aspect(\"auto\")\n",
    "im = axs[1].imshow(eopatch.mask_timeless['LULC'].squeeze())\n",
    "fig.colorbar(im, ax=axs[1], orientation='vertical')\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_aspect(\"auto\")\n",
    "del eopatch\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = './eopatches'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(10, 10))\n",
    "\n",
    "for i in tqdm(range(len(patchIDs))):\n",
    "    eopatch = EOPatch.load(f'{path_out}/eopatch_{i}', lazy_loading=True)\n",
    "    ax = axs[i//3][i%3]\n",
    "    im = ax.imshow(eopatch.mask_timeless['LULC'].squeeze())#, cmap=lulc_cmap, norm=lulc_norm)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('auto')\n",
    "    del eopatch\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "cb = fig.colorbar(im, ax=axs.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
    "# cb.ax.tick_params(labelsize=20)\n",
    "# cb.set_ticks([entry.id for entry in LULC])\n",
    "# cb.ax.set_xticklabels([entry.name for entry in LULC], rotation=45, fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
